{"tool_name":"medical_relation_extraction","contents":["biotools","bioschemas"],"fetched_metadata":{"biotools":{"id":"medical_relation_extraction","home":"https://github.com/chentao1999/MedicalRelationExtraction","license":"MIT","summary":"A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning.\n\nThe depository support training and testing BERT-CNN model on three medical relation extraction corpora: BioCreative V CDR task corpus, traditional Chinese medicine literature corpus, and i2b2 temporal relation corpus.\n\nThis is an implementation of BERT-CNN model used in our paper \"A General Approach for Improving Deep Learning-based Medical Relation Extraction using a Pre-trained Model and Fine-tuning\".","addition_date":"2020-01-14T20:15:54Z","last_update_date":"2020-12-23T08:26:18Z","tool_type":["Command-line tool"]},"bioschemas":{"name":"medical relation extraction","home":"https://bio.tools/medical_relation_extraction","license":"MIT","summary":"A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning.\n\nThe depository support training and testing BERT-CNN model on three medical relation extraction corpora: BioCreative V CDR task corpus, traditional Chinese medicine literature corpus, and i2b2 temporal relation corpus.\n\nThis is an implementation of BERT-CNN model used in our paper \"A General Approach for Improving Deep Learning-based Medical Relation Extraction using a Pre-trained Model and Fine-tuning\".","tool_type":"sc:SoftwareApplication"}}}