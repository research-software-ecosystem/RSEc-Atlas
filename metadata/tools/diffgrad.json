{"tool_name":"diffgrad","contents":["biotools","bioschemas"],"fetched_metadata":{"biotools":{"id":"diffGrad","home":"https://github.com/shivram1987/diffGrad","license":"MIT","summary":"An Optimization Method for Convolutional Neural Networks.\n\nAbstract Stochastic Gradient Decent (SGD) is one of the core techniques behind the success of deep neural networks","addition_date":"2020-01-14T19:32:19Z","last_update_date":"2020-12-22T07:10:47Z"},"bioschemas":{"name":"diffGrad","home":"https://bio.tools/diffGrad","license":"MIT","summary":"An Optimization Method for Convolutional Neural Networks.\n\nAbstract Stochastic Gradient Decent (SGD) is one of the core techniques behind the success of deep neural networks","tool_type":"sc:SoftwareApplication"}}}